<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<!-- thingies -->
<title>Eduard Trulls - Google</title>
<meta http-equiv="content-language" content="en" />
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="keywords" content="eduard trulls, google, epfl, cvlab, robotics, autonomous navigation, iri, Institut de Robòtica, computer vision, machine learning, stereo, appearance descriptors, sift, deep learning" />
<meta http-equiv="Pragma" content="no-cache" />
<!--<link rel="icon" type="image/png" href="http://www.iri.upc.edu/images/common/favicon.png" />-->
<!--<link rel="shortcut icon" href="http://www.iri.upc.edu/images/common/favicon.png" />-->

<!-- CSS -->
<link rel="stylesheet" type="text/css" href="css/style.css" />

<!-- analytics stuff -->
<script type="text/javascript">

var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-8343600-2']);
_gaq.push(['_trackPageview']);

(function() {
 var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
 ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
 var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
 })();

</script>
</head>

<body style="margin-top: 0; padding-top: 0; ">
<div id="top_bar">
	<div id="inside_top_bar">
		<div style="display: flex; align-items: flex-end;">
			<div id="my_name">Eduard Trulls</div>
			<div id="my_links">
				<a name="code"></a><a href="https://github.com/etrulls">GitHub</a> /
				<a href="https://www.linkedin.com/in/eduard-trulls-84935865/">LinkedIn</a> /
				<a href="http://scholar.google.com/citations?user=OKZC1CYAAAAJ">Google Scholar</a> /
				<a href="mailto:eduard.trulls@gmail.com">E-mail</a>
			</div>
		</div>
	</div>
</div>
<div id="body">
	<div id="content">
		<div style="display: flex; align-items: center;">
			<div style="float: left; vertical-align: middle;">
				<img src="img/foto-slc-crop.png" alt="mug" title="hi~" style="background-color: white; border-radius: 50%; width: 125px; border: none;" />
			</div>
			<div style="float: left; padding-left: 2em; vertical-align: middle; width: 100%;">
				<p>I am a Research Scientist at Google Zurich, working on Machine Learning for visual recognition. 
				Before that I was a post-doc at the <a href="http://cvlab.epfl.ch/">Computer Vision Lab</a> at EPFL in Lausanne, Switzerland, working with <a href="http://people.epfl.ch/pascal.fua/bio?lang=en">Pascal Fua</a>. I obtained my PhD from the <b>Institute of Robotics</b> in Barcelona, Spain, co-advised by <a href="http://www.iri.upc.edu/people/fmoreno/">Francesc Moreno</a> and <a href="http://www.iri.upc.edu/people/sanfeliu/">Alberto Sanfeliu</a>. Before my PhD I worked in mobile robotics.</p>
			</div>
		</div>

		<div style="clear: both;"></div>

		<div style="width: 100%">
			<a name="news"></a><h1>News</h1>
			<div>
				<ul style="padding: 0 1em;">
					<li><b>July 2023:</b> Serving as Senior PC member for AAAI'24 and AC for 3DV'24.</li>
					<li><b>July 2023:</b> GECCO accepted at ICCV'23.</li>
					<li><b>June 2023:</b> Received outstanding reviewer award for CVPR'23.</li>
					<li><b>June 2023:</b> Published SNAP to arxiv.</li>
  				<li><b>June 2023:</b> Held the 2023 Image Matching Workshop.</li>
          <li><b>April 2023:</b> Launched the <a href="https://www.kaggle.com/competitions/image-matching-challenge-2023/overview">2023 Image Matching Challenge at Kaggle</a>.</li>
					<li><b>March 2023:</b> Published GECCO to arxiv.</li>
   				<li><b>June 2022:</b> Published TUSK paper on arXiv.</li>
					<!--<li><b>May 2021:</b> Announcing the <a href="https://www.cs.ubc.ca/research/image-matching-challenge/current/">2021 version</a> of the Image Matching Challenge. With two new datasets! Also the <a href="https://simlocmatch.com/">Synthetic Matching Challenge</a> by our colleagues at Facebook.</li>
					<li><b>March 2021:</b> New paper on correspondence estimation with transformers.</li>
					<li><b>September 2020:</b> Serving as Senior Program Committee member for <a href="https://aaai.org/Conferences/AAAI-21/">AAAI'21</a>.</li>
					<li><b>September 2020:</b> Benchmark paper accepted to IJCV, DISK accepted to NeurIPS'20 as a spotlight!</li>
          <li><b>June 2020:</b> Received outstanding reviewer award for CVPR'20.</li>
					<li><b>June 2020:</b> New arxiv paper on local feature learning with policy gradient.</li>
					<li><b>June 2020:</b> Co-hosted the second edition of the CVPR Image Matching <a href="https://image-matching-workshop.github.io/">workshop</a>/<a href="https://vision.uvic.ca/image-matching-challenge">challenge</a>. Livestream <a href="https://youtu.be/UQ4uJX7UDB8">here</a>.</li>
					<li><b>February 2020:</b> One paper accepted to CVPR'20, one paper uploaded to arxiv.</li>
					<li><b>February 2020:</b> Announcing the second edition of the <a href="https://vision.uvic.ca/image-matching-challenge/">Image Matching Challenge</a>, open-sourced <a href="https://github.com/vcg-uvic/image-matching-benchmark">benchmark</a>.</li>-->
				</ul>
			</div>

			<br />

			<a name="papers"></a><h1>Publications</h1>
			<div style="color: #777; font-size: 0.85em;">Note: The top computer vision conferences (CVPR, ICCV, ECCV) are highly competitive, with low acceptance rates: 25%. You might be interested in the <a href="http://scholar.google.com/citations?view_op=top_venues&amp;hl=en&amp;vq=eng_computervisionpatternrecognition">Google Scholar Metrics</a>.</div><br />

			<div class="paper-teaser"><img src="img/cover-snap.png" alt="[img]"/></div>
			<div class="paper-data">
				<div class="paper-title"><a href="https://arxiv.org/abs/2306.05407">SNAP: Self-Supervised Neural Maps for Visual Positioning and Semantic Understanding</a></div>
				<div class="paper-authors">Paul-Edouard Sarlin, <b>Eduard Trulls</b>, Marc Pollefeys, Jan Hosang, Simon Lynen</div>
				<div class="paper-venue">In arXiv, 2023</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-gecco.png" alt="[img]"/></div>
			<div class="paper-data">
				<div class="paper-title"><a href="https://arxiv.org/abs/2303.05916">GECCO: Geometrically-Conditioned Point Diffusion Models</a></div>
				<div class="paper-authors">Michał J. Tyszkiewicz, Pascal Fua, <b>Eduard Trulls</b></div>
				<div class="paper-venue">In ICCV, 2023</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-tusk.png" alt="[img]"/></div>
			<div class="paper-data">
				<div class="paper-title"><a href="https://arxiv.org/abs/2206.08460">TUSK: Task-Agnostic Unsupervised Keypoints</a></div>
				<div class="paper-authors">Yuhe Jin, Weiwei Sun, Jan Hosang, <b>Eduard Trulls</b>, Kwang Moo Yi</div>
				<div class="paper-venue">In NeurIPS, 2022</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-cotr.png" alt="[img]"/></div>
			<div class="paper-data">
				<div class="paper-title"><a href="https://arxiv.org/abs/2103.14167">COTR: Correspondence Transformer for Matching Across Images</a></div>
				<div class="paper-authors">Wei Jiang, <b>Eduard Trulls</b>, Jan Hosang, Andrea Tagliasacchi, Kwang Moo Yi</div>
				<div class="paper-venue">In ICCV, 2021 (oral)</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-disk.png" alt="[img]"/></div>
			<div class="paper-data">
				<div class="paper-title"><a href="https://arxiv.org/abs/2006.13566">DISK: Learning local features with policy gradient</a></div>
				<div class="paper-authors">Michał J. Tyszkiewicz, Pascal Fua, <b>Eduard Trulls</b></div>
				<div class="paper-venue">NeurIPS, 2020 (spotlight oral)</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-benchmark.png" alt="[img]"/></div>
			<div class="paper-data">
				<div class="paper-title"><a href="https://arxiv.org/abs/2003.01587">Image Matching across Wide Baselines: from Paper to Practice</a></div>
				<div class="paper-authors">Yuhe Jin, Dmytro Mishkin, Anastasiia Mishchuck, Jiri Matas, Pascal Fua, Kwang Moo Yi, <b>Eduard Trulls</b></div>
				<div class="paper-venue">IJCV, 2020</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-acne.png" alt="[img]"/></div>
			<div class="paper-data">
				<div class="paper-title"><a href="https://arxiv.org/abs/1907.02545">Attentive Context Normalization for Robust Permutation-Equivariant Learning</a></div>
				<div class="paper-authors">Weiwei Sun, Wei Jiang, <b>Eduard Trulls</b>, Andrea Tagliasacchi, Kwang Moo Yi</div>
				<div class="paper-venue">In CVPR, 2020</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-iccv19-logpol.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title"><a href="pdf/iccv-2019-logpol.pdf">Beyond Cartesian Representations for Local Descriptors</a></div>
				<div class="paper-authors">Patrick Ebel, Anastasiia Mishchuk, Kwang Moo Yi, Pascal Fua, <b>Eduard Trulls</b></div>
				<div class="paper-venue">In ICCV, 2019</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-lin.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title"><a href="pdf/iccv-2019-linearized.pdf">Linearized Multi-Sampling for Differentiable Image Transformation</a></div>
				<div class="paper-authors">Wei Jiang, Weiwei Sun, Andrea Tagliasacchi, <b>Eduard Trulls</b>, Kwang Moo Yi</div>
				<div class="paper-venue">In ICCV, 2019 (oral)</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-yuki.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title"><a href="https://papers.nips.cc/paper/7861-lf-net-learning-local-features-from-images.pdf">LF-Net: Learning Local Features from Images</a></div>
				<div class="paper-authors">Yuki Ono, <b>Eduard Trulls</b>, Pascal Fua, Kwang Moo Yi</div>
				<div class="paper-venue">NeurIPS, 2018</div>
				<div class="paper-links">
					<a href="https://github.com/vcg-uvic/lf-net-release">code</a> /
					<a href="posters/lfnet-poster-rev3.pdf">poster</a>
				</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-corr.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title"><a href="https://arxiv.org/abs/1711.05971">Learning to Find Good Correspondences</a></div>
				<div class="paper-authors">Kwang Moo Yi(*), <b>Eduard Trulls(*)</b>, Yuki Ono, Mathieu Salzmann, Vincent Lepetit, Pascal Fua (*: equal contribution)</div>
				<div class="paper-venue">Computer Vision and Pattern Recognition (CVPR), 2018 (oral presentation: 2.1% acceptance rate)</div>
				<div class="paper-links">
					<a href="https://github.com/vcg-uvic/learned-correspondence-release">code</a> /
					<a href="posters/cvpr18.pdf">poster</a> /
					<a href="slides/cvpr18_slides.pdf">slides</a>
				</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-eccv16.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title"><a href="pdf/eccv16-lift.pdf">LIFT: Learned Invariant Feature Transform</a></div>
				<div class="paper-authors">Kwang Moo Yi(*), <b>Eduard Trulls(*)</b>, Vincent Lepetit, Pascal Fua (*: equal contribution)</div>
				<div class="paper-venue">European Conference on Computer Vision (ECCV), 2016</div>
				<div class="paper-links">
					<a href="https://github.com/cvlab-epfl/tf-lift">code (tf)</a> /
					<a href="https://github.com/cvlab-epfl/LIFT">code (theano, deprecated)</a> /
					<a href="posters/eccv16.pdf">poster</a> /
					<a href="sites/eccv16/index.html">video</a> /
					<a href="sites/eccv16/lift_supplementary.pdf">supplemental</a>
				</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-cvpr16.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title"><a href="pdf/cvpr-2016-aerial.pdf">Learning to Match Aerial Images with Deep Attentive Architectures</a></div>
				<div class="paper-authors">Hani Altwaijry, <b>Eduard Trulls</b>, James Hays, Pascal Fua, Serge Belongie</div>
				<div class="paper-venue">Conference on Computer Vision and Pattern Recognition (CVPR), 2016</div>
				<div class="paper-links">
					<a href="posters/cvpr16.pdf">poster</a>
				</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-book.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title">Dense Segmentation-aware Descriptors</div>
				<div class="paper-authors"><b>Eduard Trulls</b>, Iasonas Kokkinos, Alberto Sanfeliu and Francesc Moreno-Noguer</div>
				<div class="paper-venue">Chapter in Dense Image Correspondences for Computer Vision, Eds. C. Liu and T. Hassner, Springer, 2015</div>
				<div class="paper-links">
					<a href="https://www.springer.com/gp/book/9783319230474">link</a>
				</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-mining.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title"><a href="pdf/iccv-2015-deepdesc.pdf">Discriminative Learning of Deep Convolutional Feature Point Descriptors</a></div>
				<div class="paper-authors">Edgar Simo-Serra(*), <b>Eduard Trulls(*)</b>, Luis Ferraz, Iasonas Kokkinos, Pascal Fua and Francesc Moreno-Noguer (*: equal contribution)</div>
				<div class="paper-venue">International Conference on Computer Vision (ICCV), 2015</div>
				<div class="paper-links">
					<a href="https://github.com/etrulls/deepdesc-release">code</a> /
					<a href="posters/iccv15.pdf">poster</a> /
					<a href="pdf/iccv-2015-deepdesc-supp.pdf">supplemental</a> /
					<a href="spotlights/spotlight-iccv-2015.mp4">spotlight</a>
				</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-tesi-2-small.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title"><a href="pdf/thesis-color-small.pdf">Enhancing low-level features with mid-level cues</a></div>
				<div class="paper-authors"><b>Eduard Trulls</b></div>
				<div class="paper-venue">PhD thesis, 2015</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-cvpr14b.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title"><a href="pdf/trulls-cvpr-2014.pdf">Segmentation-aware Deformable Part Models</a></div>
				<div class="paper-authors"><b>Eduard Trulls</b>, Stavros Tsogkas, Iasonas Kokkinos, Alberto Sanfeliu, Francesc Moreno-Noguer</div>
				<div class="paper-venue">Conference on Computer Vision and Pattern Recognition (CVPR), 2014</div>
				<div class="paper-links">
					<a href="posters/cvpr14.pdf">poster</a> /
					<a href="https://vimeo.com/109568297">spotlight </a>
				</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-cvpr13.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title"><a href="pdf/trulls-cvpr-2013.pdf">Dense segmentation-aware descriptors</a></div>
				<div class="paper-authors"><b>Eduard Trulls</b>, Iasonas Kokkinos, Alberto Sanfeliu, Francesc Moreno-Noguer</div>
				<div class="paper-venue">Conference on Computer Vision and Pattern Recognition (CVPR), 2013</div>
				<div class="paper-links">
					<a href="https://github.com/etrulls/softseg-descriptors-release">code</a> /
					<a href="posters/cvpr13.pdf">poster</a> /
					<a href="spotlights/cvpr13-spotlight.pdf">spotlight</a>
					<!--<a href="sites/cvpr13/index.html">project page</a>-->
				</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-eccv12.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title"><a href="pdf/trulls-eccv-2012.pdf">Spatiotemporal descriptor for wide-baseline stereo reconstruction of non-rigid and ambiguous scenes</a></div>
				<div class="paper-authors"><b>Eduard Trulls</b>, Alberto Sanfeliu, Francesc Moreno-Noguer</div>
				<div class="paper-venue">European Conference on Computer Vision (ECCV), 2012</div>
				<div class="paper-links">
					<a href="posters/eccv12.pdf">poster</a> /
					<a href="https://vimeo.com/109568298">spotlight</a>
					<!--<a href="sites/eccv12/index.html">project page</a>-->
				</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-jfr11.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title"><a href="pdf/trulls-jfr-2011.pdf">Autonomous navigation for mobile service robots in urban pedestrian environments</a></div>
				<div class="paper-authors"><b>Eduar Trulls</b>, Andreu Corominas Murtra, Joan Pérez-Ibarz, Gonzalo Ferrer, Dizan Vasquez, Josep Maria Mirats-Tur, Alberto Sanfeliu</div>
				<div class="paper-venue">Journal of Field Robotics, 2011</div>
				<!--<a href="sites/jfr11/index.html">project page</a>-->
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-simpar.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title"><a href="pdf/corominas-simpar-2010.pdf">Efficient use of 3D environment models for mobile robot simulation and localization</a></div>
				<div class="paper-authors">Andreu Corominas Murtra, <b>Eduard Trulls</b>, Josep Maria Mirats-Tur, Alberto Sanfeliu</div>
				<div class="paper-venue">International Conference on Simulation, Modelling, and Programming for Autonomous Robots (SIMPAR), 2010. Also in Simulation, Modelling, and Programming for Autonomous Robots, Lecture Notes in Computer Science, 2010.</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-iros10.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title"><a href="pdf/corominas-iros-2010.pdf">Autonomous navigation for urban service mobile robots</a></div>
				<div class="paper-authors">Andreu Corominas Murtra, <b>Eduard Trulls</b>, Oscar Sandoval, Joan Perez, Dizan Vasquez, Josep Maria Mirats-Tur, Miquel Ferrer, Alberto Sanfeliu</div>
				<div class="paper-venue">International Conference on Intelligent Robots and Systems (IROS), 2010</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-iros09.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title"><a href="pdf/valencia-iros-2009.pdf">3D Mapping for Urban Service Robots</a></div>
				<div class="paper-authors">Rafael Valencia-Carreño, Ernesto Teniente, <b>Eduar Trulls</b>, Juan Andrade-Cetto</div>
				<div class="paper-venue">International Conference on Intelligent Robots and Systems (IROS), 2009</div>
			</div>
			<div class="clean"></div>

			<div class="paper-teaser"><img src="img/cover-workshop-iros09.png" alt="[img]" /></div>
			<div class="paper-data">
				<div class="paper-title"><a href="pdf/cetto-iros-2009-workshop.pdf">Combination of Distributed Camera Network and Laser-based 3D Mapping for Urban Service Robotics</a></div>
				<div class="paper-authors">Juan Andrade-Cetto, Agustín Ortega, Ernesto Teniente, <b>Eduard Trulls</b>, Rafael Valencia, Alberto Sanfeliu</div>
				<div class="paper-venue">Workshop on Network Robot Systems, International Conference on Intelligent Robots and Systems (IROS), 2009</div>
			</div>
			<div class="clean"></div>
		</div>
	</div>

	<div id="footer_spacer"></div>

	<div id="footer">
		<div id="footer_contents">
			<div id="footer_left">&nbsp;</div>
			<div id="footer_right">
				<!--last updated: june 2020 &nbsp;/&nbsp;-->
				<a href=".">home</a> &nbsp;/&nbsp;
				<a href="http://validator.w3.org/check?uri=etrulls.github.io">validate</a>
			</div>
			<div class="clean"></div>
		</div>
	</div>
</div>
</body>
</html>
